---
title: "p8105_hw6_hj2660"
author: "Hyun Jin Jung"
date: "2023-12-2"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%")

theme_set(theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5)))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis")

set.seed(1)
```

### Problem 1

In the data cleaning code below we create a `city_state` variable, change `victim_age` to numeric, modifiy victim_race to have categories white and non-white, with white as the reference category, and create a `resolution` variable indicating whether the homicide is solved. Lastly, we filtered out the following cities: Tulsa, AL; Dallas, TX; Phoenix, AZ; and Kansas City, MO; and we retained only the variables `city_state`, `resolution`, `victim_age`, `victim_sex`, and `victim_race`.

```{r q1_data_cleaning}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) |> 
  filter(victim_race %in% c("White", "Black")) |> 
  filter(!(city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO"))) |> 
  select(city_state, resolution, victim_age, victim_sex, victim_race)
```

Next we fit a logistic regression model using only data from Baltimore, MD. We model `resolved` as the outcome and `victim_age`, `victim_sex`, and `victim_race` as predictors. We save the output as `baltimore_glm` so that we can apply `broom::tidy` to this object and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims.

```{r q1_glm_baltimore}
baltimore_glm = 
  filter(homicide_df, city_state == "Baltimore, MD") |> 
  glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial(), data = _)

baltimore_glm |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(OR, OR_CI_lower, OR_CI_upper) |>
  knitr::kable(digits = 3)
```

Below, by incorporating `nest()`, `map()`, and `unnest()` into the preceding Baltimore-specific code, we fit a model for each of the cities, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. We show the first 5 rows of the resulting dataframe of model results.

```{r q1_glm_all_cities}
model_results = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(resolution ~ victim_age + victim_sex + victim_race, 
                             family = binomial(), data = df)),
    tidy_models = map(models, broom::tidy)) |> 
  select(-models, -data) |> 
  unnest(cols = tidy_models) |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_lower, OR_CI_upper)

model_results |>
  slice(1:5) |> 
  knitr::kable(digits = 3)
```

Below we generate a plot of the estimated ORs and CIs for each city, ordered by magnitude of the OR from smallest to largest. From this plot we see that most cities have odds ratios that are smaller than 1, suggesting that crimes with male victims have smaller odds of resolution compared to crimes with female victims after adjusting for victim age and race. This disparity is strongest in New yrok. In roughly half of these cities, confidence intervals are narrow and do not contain 1, suggesting a significant difference in resolution rates by sex after adjustment for victim age and race. 

```{r q1_plot}
model_results |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


# Problem 2

Load Central Park weather data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

Fitting regression model
```{r}
fit = lm(tmax ~ tmin + prcp, data = weather_df)

summary(fit)
```

Create sample for Bootstrap
```{r}
boot_sample = function(weather_df){
  sample_frac(weather_df, replace = TRUE)
}

boot_straps =
  tibble(strap_number = 1:5000) |> 
  mutate(
    strap_sample = map(strap_number, \(i) boot_sample(weather_df))
  )
```


Estimates of $\hat{r}^2$ and $\log(\hat{\beta}_1 * \hat{\beta}_2)$ for each sample.
```{r}
r_squared = boot_straps |>
  mutate(
    models = map(strap_sample, \(weather_df) lm(tmax ~ tmin + prcp, data = weather_df)),
    rs_results = map(models, broom::glance)) |>
  select(strap_number, rs_results) |>
  unnest(rs_results) |>
  select(strap_number, r_squared = r.squared) 

log_estimate = 
  boot_straps |> 
  mutate(
    models = map(strap_sample, \(weather_df) lm(tmax ~ tmin + prcp, data = weather_df)),
    log_results = map(models, broom::tidy),
  ) |> 
  select(strap_number, log_results) |> 
  unnest(log_results) |>
  select(strap_number, term, estimate) |> 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) |> 
  mutate(log_beta1_beta2 = ifelse(tmin * prcp > 0, log(tmin * prcp), NA)) |> 
  select(strap_number, log_beta1_beta2)

boot_results =
  inner_join(r_squared, log_estimate)
```

The warning `NaNs produced` is triggered when the expression `log(tmin * prcp)` results in non-positive values, so I replaced those NAN values with NA using `ifelse`. Then, used `inner_join` to combine two results.

Plot the distribution of $\hat{r}^2$ and $\log(\hat{\beta}_1 * \hat{\beta}_2)$.
```{r}
boot_results |> 
  ggplot(aes(x = r_squared)) + 
  geom_density() +
  labs(title = "R_squared Distribution")

boot_results |> 
  ggplot(aes(x = log_beta1_beta2)) + 
  geom_density() +
  labs(title = "Log(beta1 * beta2) Distribution")
```

These density plots visually represent the distribution of the bootstrap estimates for $\hat{r}^2$ and $\log(\hat{\beta}_1 * \hat{\beta}_2)$. The plot for $\hat{r}^2$ shows a distribution that is very close to normal, with a slight left-skewness. The values span a range from approximately 0.865 to 0.952.

In contrast, the plot for $\log(\hat{\beta}_1 \cdot \hat{\beta}_2)$ shows a distinct left-skewness. Several rows had to be removed due to non-finite values, as indicated by the warning message `NaNs produced`. This issue arose from attempting to take the logarithm of negative values.

 
Calculate 95% confidence intervals for $\hat{r}^2$ and $\log(\hat{\beta}_1 * \hat{\beta}_2)$.
```{r}
boot_results |> 
  summarize(
    r_squared_CI_lower = quantile(r_squared, 0.025),
    r_squared_CI_upper = quantile(r_squared, 0.975),
    log_beta1_beta2_CI_lower = quantile(log_beta1_beta2, 0.025, na.rm = TRUE),
    log_beta1_beta2_CI_upper = quantile(log_beta1_beta2, 0.975, na.rm = TRUE)
  ) |> 
  knitr::kable(digits = 3)
```

We are 95% confident that the true $\hat{r}^2$ lies between 0.889 and 0.941, and we are 95% confident that the true $\log(\hat{\beta}_1 * \hat{\beta}_2)$ lies between -8.982 and -4.602.

# Problem 3

Import and clean data
```{r}
bw_df = read_csv("data/birthweight.csv") |>
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace))

colSums(is.na(bw_df))
```
Converted numeric to factor. Then used `colSums(is.na(bw_df))` to see if there's any missing data, and there wasn't.

Fitting regression model
```{r}
full_model = lm(bwt ~., data = bw_df)

summary(full_model)
```
I constructed a regression model for birthweight by including all available variables as predictors. Each of these variables is considered meaningful in contributing to the variation in a child's birthweight.


```{r}
bw_df |> 
  modelr::add_residuals(full_model) |> 
  modelr::add_predictions(full_model) |> 
  ggplot(aes(x = pred, y=resid)) + 
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm") +
  labs(x = "Fitted values", 
       y = "Residuals", 
       title = "Model Residuals vs. Fitted Values")
```

This plot enables the observation that the residuals scatter around 0.

```{r}
#use length at birth and gestational age as predictors (main effects only)
model_1 = lm(bwt ~ blength + gaweeks, data = bw_df)

#use head circumference, length, sex, and all interactions (including the three-way interaction) 
model_2 = lm(bwt ~ (bhead + blength + babysex)^3, data = bw_df)
```


```{r}
cv_df = crossv_mc(bw_df, 100) |>
  mutate(
    train = map(train, as_tibble), 
    test = map(test, as_tibble))
```
Made cross-validation on the `bw_df` dataset, creating 100 random splits into training and testing sets. 

Compare your model to two others:
```{r}
cv_df |>
  mutate(
    proposed_mod = map(train, \(df) lm(bwt ~., data = df)),
    main_effect_mod = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    interaction_mod = map(train, \(df) lm(bwt ~ bhead + blength + babysex + bhead * blength + blength* babysex + bhead* babysex + bhead * blength * babysex, data = df))
  ) |>
  mutate(
    rmse_proposed = map2_dbl(proposed_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_main = map2_dbl(main_effect_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_interaction = map2_dbl(interaction_mod, test, \(mod, df) rmse(model = mod, data = df)),
  ) |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() +
  labs(x = "Model",
       y = "RMSE",
       title = "Models vs RMSE")
```

The proposed model, utilizing all predictors, achieved the lowest RMSE, signifying the most accurate predictions on the test data. The main effect model, with only birth length and gestational age as predictors, yielded less accurate predictions. The interaction model, incorporating all interactions and the three-way interaction, showed a moderately higher RMSE, indicating less accuracy compared to the full predictor set.

In summary, lower RMSE values signify better predictive performance. However, it's crucial to consider the specific context of the analysis and modeling goals.